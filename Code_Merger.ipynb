{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384ce202",
   "metadata": {},
   "source": [
    "### Merging Personalized Dataframes back into Generalized DataFrame ###\n",
    "\n",
    "The purpose of this notebook is to merge together perosnalized dataframes into a shared dataframe. Edits made by individuals on their own copy of the shared dataframe are saved to their personalized dataframes. These personalized dataframes can then be used to start this process anew. Begin by importing the relevant libraries and defining a method that is relevant for merging the columns of the intermittent merged dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def tagMerge(compTag, umbTag, df, clean) : # a function that merges several existing tags together into one common tag.\n",
    "    tagMat = [ # list comp within list comp\n",
    "        [\n",
    "            df[tag][ind] for tag in compTag # copy each tag value for the relevant component tags\n",
    "        ] for ind, row in df.iterrows() # list comprehension over no. of rows\n",
    "        \n",
    "    ]\n",
    "    df[umbTag] = [np.lcm.reduce(tagRow) for tagRow in tagMat] # set new column equal\n",
    "    if(clean) : # are we purging all of the old columns?\n",
    "        if(umbTag in compTag) : # is umbrella tag one of our component tags?\n",
    "            compTag.remove(umbTag) # remove it so that we don't undo all of our efforts\n",
    "        df.drop(columns = compTag, inplace = True) # drop all unnecessary tags.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7d8f5",
   "metadata": {},
   "source": [
    "#### Setting Workspace and Loading Files ####\n",
    "\n",
    "This block reads in the name of the family of files to be merged together. Adjust the first line of this block as necessary when merging different data frames. The block then loads in both the general and the personalized data frames of each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8833ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "workingFile = 'example' # which file are we working on today\n",
    "\n",
    "users = []\n",
    "f = open(\"users.txt\", \"r\")\n",
    "for line in f: # read through every user\n",
    "    read = line.split()\n",
    "    users.append(read[0])\n",
    "f.close()\n",
    "\n",
    "mainDF = pd.read_csv(f'{workingFile}.csv') # load in general use dataframe\n",
    "persDFs = [pd.read_csv(f'{workingFile}{user}.csv') for user in users] # Load in personalized dataframes as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06111fa",
   "metadata": {},
   "source": [
    "#### Merging Dataframes ####\n",
    "\n",
    "The merging occurs by doing an outer merge between the general dataframe and each of the personalized dataframes in some order. Each merge creates a number of redundant columns in the resulting dataframe, so the `tagMerge` function is used to reduce the dataframe back down to the number of columns that it had initially. These merges use the proper mathematical reasoning required for the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in persDFs : # iterate over each personalized dataframe in the list\n",
    "    scraDF = mainDF.merge(df, how = 'outer', on = ['text', 'id', 'index', 'section'], suffixes = [None,'_p']) # merge each personalized dataframe with main dataframe\n",
    "    for tag in mainDF.columns : # Merge together tags that had previously existed in dataframe\n",
    "        if(tag in ['text', 'completion', 'id', 'index', 'section']) : # don't deal with this non-tag column\n",
    "            continue\n",
    "        else:\n",
    "            scraDF = tagMerge([tag,f'{tag}_p'],tag,scraDF,True)\n",
    "        mainDF = scraDF # move current scratch df onto main df prior to next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48474d4c",
   "metadata": {},
   "source": [
    "#### Saving Final Dataframe ####\n",
    "\n",
    "Once the personalized dataframes have all been merged together, we can re-save the main dataframe to its `.csv` file. This ends our use of the code merging method. From this point, you are cleared to use `qualCoder.ipynb` where you may make changes to the main dataframe before saving it over your personalized copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF.to_csv(f'{workingFile}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1802ea6",
   "metadata": {},
   "source": [
    "### MANUAL OVERWRITE ###\n",
    "\n",
    "**WARNING:** Only use this block when you wish to work on the main dataset, but you know for a fact that the datasets of your fellow coders are outdated. In this circumstance merging with them would undo some of your work, so with their consent, you will replace their outdated dataframes with your own. The main utility of this comes along when we wish to begin pruning our tags rather than expanding them. My code is mainly designed to be inclusive of all contributions and when one user is attempting to discard useless tags that they don't like, merging will only undo their work as the other users will still have\n",
    "those tags written.\n",
    "\n",
    "\n",
    "When you do this, be sure to `git add` all three personalized dataframes when you push to github. If you do this, then the next time someone pulls from off of github, they will be given the updated overwrite of their own dataframe. If you don't add their work, then they will continue working on their 'outdated' file and you risk merging ineffectively during a future session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84258292",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Are you sure you wish to overwrite all other data frames with your personalized version? (y/n) \") # seek verification\n",
    "if(query.lower() == 'y') : # acquired\n",
    "    print(users)\n",
    "    useNo = input(\"\\nPlease enter integer value for your position in the user list: \")\n",
    "    if useNo in range(len(users)): # verify that correct int was entered\n",
    "        copy_df = pd.read_csv(f'{workingFile}{users[int(useNo)]}.csv') # load in core copier\n",
    "        for user in users: # look at each user\n",
    "            copy_df.to_csv(f'{workingFile}{user}.csv', index = False) # paste core copier over each dataframe\n",
    "    else: # missed input\n",
    "        print(\"\\nImproper integer input. Please try again.\")\n",
    "    print(\"\\nData frame has been saved.\")\n",
    "    codeDF.to_csv(f'{workingFile}.csv', index = False) # overwrite .csv with current version\n",
    "else :  # denied\n",
    "    print(\"\\nData frames were not overwritten.\") # state that save did not occur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
